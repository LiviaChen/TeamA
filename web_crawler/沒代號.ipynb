{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 台股攻破14000點　台積電休息、聯電帶頭衝\n",
      "\n",
      "\n",
      "記者陳心怡／綜合報導美股周三標普、費半兩大指數連續兩個交易日創新高，早盤台積電開平低盤，大盤指數走跌，不過隨著電子股表現穩健，10點過後左右，指數由跌翻漲，10點13分大盤指數順利攻破14000點大關，最高來到14019點，再創台股新高紀錄。雖然權值股龍頭台積電雖平盤震盪小跌，但聯電挺身而出漲幅近5%，成為衝鋒領頭羊。台積電ADR 2日下跌逾1.29％，以99.54美元作收，台積電（2330）今日早盤以499.5元開出，賣壓逐步出籠，盤中一度下探至495元價位。其他權值股方面，傳產族群持穩，南亞早盤勁揚逾 2%，為台塑四寶中表現最為強勢；台泥、亞德客 - KY、國巨、上銀、宏碁等也都有 1% 以上漲幅；不過，聯發科、鴻海、日月光投控、中租 - KY 等表現偏弱勢。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201203/1868189.htm\n",
      "\n",
      "                                    2020-12-03 10:17                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 00878成分股新增台泥、國巨　11月績效奪雙冠王\n",
      "\n",
      "\n",
      "記者陳心怡／台北報導目前台股規模、投資人數最多的ESG國民ETF — 國泰永續高股息ETF（00878）自7月上市以來廣受市場認同，霸佔每月成交量第一寶座，根據CMoney統計，11月份漲幅達6.87%，高居配息型台股ETF投資效率之冠，另外，00878今（1）日跟隨追蹤指數進行換股，共剔除大聯大（3702）、力成（6239）、寶成（9904）三檔，新增台泥（1101）、國巨（2327）及可成（2474）。另外，觀察到一樣為ESG ETF的富邦公司治理（00692）、及元大臺灣ESG永續（00850），11月績效漲逾一成，表現比台灣50 ETF更優異。00878這次調整是根據指數規則進行每半年度調整，MSCI歷經嚴謹的調查研究，給予成分股合理的ESG評等，如台泥在2018年底時成為全世界首家通過BS 8001循環經濟認證的水泥業，2019年更超標達成溫室氣體排放量控制，提早實現2030年的目標，故ESG評級被調高至BB級。國泰投信表示，好公司長期一定會有好表現，11月份00878的表現驗證了具備ESG概念的配息型台股ETF，是投資人存ETF的首選，靠ESG選績優好股，才能存得安心、抱得放心、領得開心，透過中長線持有，或以定期定額的方式，就能達到存ETF領息、資產增值的效果。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201201/1866937.htm\n",
      "\n",
      "                                    2020-12-01 18:15                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 櫃買「權值股Top10」揭曉　夯股環球晶、合一上榜！\n",
      "\n",
      "\n",
      "記者林妤柔／綜合報導分析師陳相州在粉絲團《股添樂 股市新觀點》表示，櫃買指數今天創13年新高，他觀察上櫃指數「前十大成分股」，發現投資價值不亞於上市公司，冠軍為近期最夯的環球晶（6488），連一度榮登生技股王的合一（4743）也有入榜。陳相州指出，雖然櫃買市場常被認為是內資主力的活躍場所、小散戶的傷心地，不過撇除小型股，觀察櫃買權值前十名的股票，其實都是各產業非常具代表性的企業，投資價值絕對不亞於上市公司。陳相州舉例，這些股票多半具有非常好的公司治理，也具備穩定的配息條件；第一名的環球晶市值甚至比台泥、元大、華南金都還要高，「如果這些股票是上市公司，前3名篤定是台灣50的成分股」。不過，這些股票和上市公司最大的差別在於股本普遍不到50億，體質非常「輕盈」，陳相州表示，這些股票在多頭時期漲起來都特別快，不過相對地，空頭時期也會跌得比較快。如果對波動忍受度比較高的投資人，從上櫃股票透過市值加上公司治理來選股，是沒問題的。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201201/1866893.htm\n",
      "\n",
      "                                    2020-12-01 17:42                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 全台首座大型漁電共生！台泥砸20億...嘉義設23公頃太陽能發電場\n",
      "\n",
      "\n",
      "記者翁伊森／嘉義報導台泥嘉謙綠能公司在義竹鄉舉辦漁電共生動土典禮，為全國第1個大型漁電共生案場，預計明年7月正式發電，年發電量將達5400萬度，嘉義縣長翁章梁及台鹽董事長陳啟昱、台泥董事長張安平、能源局主秘翁素貞、漁業署副署長林國平、嘉義縣議會副議長陳怡岳、縣議員蔡瑋傑、黃金茂、義竹鄉長黃阿家等貴賓共同參與，期許此處將成為台灣的綠能供電及養殖漁業共生的標竿及典範。「以漁民的生產為主，綠能為輔。」翁章梁強調，政府為穩健發展綠能，推動國家能源轉型政策，嘉義縣政府也在國家綠能政策的引導下，審慎推動養殖漁業結合綠能的發展，秉持兼顧養殖產業發展、漁民權益、綠能發電及生態環境，促使邁向綠能、養殖產業及生態環境的永續，創造多贏的局面。張安平指出，台灣必須要有綠能，才能繼續發展下去，台泥秉持以自然為本，以人為心的理念，願意配合台灣政府發展綠能，將台灣打造為綠能島嶼，更感謝地方及中央政府及台鹽的大力協助，未來將與夥伴們共同為地球與自然努力付出，盼建造一個美麗且有希望的未來！▲嘉義義竹案場為全台首座大型漁電共生案場。（圖／記者翁伊森翻攝）台泥嘉謙綠能及台鹽綠能公司合作的漁電共生專區，自去年開始，在縣府農業處及漁電共生工作小組輔導及協助下，於今年取得農委會的核定劃設，及本府綠能設施容許使用，專區面積達77公頃，台泥及台鹽綠能允諾會以「漁業為本、綠能加值」，照顧農漁民為優先，不影響漁業生產下，透過結合綠能使漁民受惠。專區內台泥嘉謙綠能公司將投入20億元資金，設置綠源模組約23公頃，未來可以創造43MW的綠能，預計在明年7月正式發電，平均年發電量達5400萬度，可供應超過1.6萬戶家庭1年所需用電，20年累計可減少碳排放量達1550座大安森林公園每年的碳吸附量，將是一座乾淨能源的漁電共生發電場域。發展漁電的過程中，除綠能的產出，縣府在審查時也嚴格把關，未來也會落實查核，來確保養殖產業的發展、漁民的權益及生態環境的多贏；當初規劃漁電共生案場時，場址的選擇上已避開生態環境敏感區位，縣府要求以養殖為優先，保障原養殖工作者權益，台泥嘉謙綠能也保證原養殖戶具優先使用權，使用費不超過原租金的6成，使用費將作為漁場基金，回饋至漁民身上。同時，也與漁民討論因地制宜設置綠能設施，達到夏天時產生適度遮蔽減少蒸發及降溫，冬天時可以快速搭建防風棚，避免寒害損失，以及會整建塭堤及農路，並導入AI管理技術，進而改善養殖場域及促進漁業升級的加值效益，縣府未來也會查核是否落實執行。未來將有更多的漁電共生場域陸續推動，本案場是全國第一個大型案場，縣府將會協助及督責台泥及台鹽公司落實推動，建置一座兼具發展綠能發展，並優化漁業生產場域，將嘉義縣產業轉型及土地空間作最有效率的規劃利用，共同創造養殖、創能與環境三贏的綠能建設，成為台灣綠能供電及養殖漁業共生的典範。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201125/1861570.htm\n",
      "\n",
      "                                    2020-11-25 09:33                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 台泥漁電共生案場今動土　預計明年7月開始發電、電量可供1.6萬家庭\n",
      "\n",
      "\n",
      "  泥嘉謙綠能嘉義漁電共生案今日舉辦動土典禮，左二起臺鹽董事長陳啟昱、嘉義縣長翁章梁、台泥企業團董事長張安平、台泥總經理李鐘培、漁業署副署長林國平、能源局主秘翁素真。（圖／台泥提供）記者陳心怡／台北報導台灣首座漁電共生案場，「台泥嘉謙綠能嘉義漁電共生案」，今（23）日於嘉義縣舉辦動土典禮，台泥指出，預計明年7月開始正式發電，平均年發電量將達5400萬度，可供應超過1.6萬戶家庭1年所需用電。台泥企業團董事長張安平表示，嘉義漁電共生案場的啟動，不僅落實政府推動再生能源政策，也創造養殖、創能與環境三贏的綠能建設，充分體現循環經濟的精神。台泥綠能也將繼續響應行政院的漁電共生先行政策，持續投入漁電共生太陽光電的項目，逐步朝向200MW的中期目標邁進。張安平指出，今年10月可能是人類有史以來最熱的10月份，北極圈有大幅融冰滑落，未來對地球的影響目前不得而知，但我們更清楚知道發展綠能的重要性。台灣需要綠能才能繼續發展，台泥企業團非常願意配合政府的政策，協助把台灣打造成一個綠能的島，一起為大自然、為地球付出，建造出一個美麗有希望的未來。也再次感謝台鹽綠能，我們會攜手合作共同打造全台灣最漂亮、最標竿的漁電共生案場。台泥綠能在嘉義縣義竹鄉與布袋鄉交界的漁電共生案場，由臺鹽綠能統包工程，將在60公頃的塭堤上建設一座約 43MW 的太陽能電廠，保留原本的漁業，再加入光電的投產，可藉由光電產生的利益改善養殖環境，達到養殖業者漁業單位收穫不受影響，並可享有更佳租地優惠及更佳的養殖環境。該案裝置容量為43MW，預計2021年7月開始正式發電，屆時平均年發電量將達 5,400 萬度，可供應超過 1.6 萬戶家庭1年所需用電，累計20 年減少碳排放量達 1,550 座大安森林公園的碳吸附量。台泥企業團響應政府的能源轉型政策，近年積極發展能源事業，現階段台泥綠能的再生能源建設，已發電裝置量為35MW，建置中裝置為49MW、規劃中裝置量為92MW，年度發電量可達到將近 1 億 3 仟萬度電，相當於減碳量約 6 萬 9 千公噸。預計 2025 年將管理 500MW 以上的再生能源電廠。因應再生能源間歇性的特點，台泥企業團也積極投入儲能發展，近期台泥綠能攜手同集團的能元科技，得標台電「儲能自動頻率控制（AFC）調頻備轉輔助服務」、共5MW容量，就是運用儲能來調節電力系統頻率，解決電網的不穩定性。\n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201123/1860972.htm\n",
      "\n",
      "                                    2020-11-23 16:00                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 東元獎登場！生命科學家打造台灣版諾亞方舟　獲頒人文獎\n",
      "\n",
      "\n",
      "記者姚惠茹／台北報導東元科技文教基金會今（21）日舉行第27屆「東元獎」頒獎典禮，頒發科技類四大領域共七位學者獲獎，「國產學者」獲獎人數首度超越海歸派，至於人文類獎則頒發給清華大學講座教授李家維，表彰其籌畫建置「辜嚴倬雲熱帶植物保種中心」，打造台灣版諾亞方舟。今年「東元獎」科技類在「生醫／農業」、「電機／資訊／通訊」與「機械／能源／環境」領域，同時有兩位學者脫穎而出，共同平分80萬元獎金；僅「化工／材料」領域由清華大學材料科學工程學系特聘教授葉均蔚獨領風騷，主辦單位今年再度邀請中央研究院院長廖俊智擔任頒獎人。「東元獎」自1994年創設至今，頒發獎金累計超過8230萬元，陸續有155位學者專家獲得殊榮，其中「生醫／農業」領域由高雄醫學大學講座教授兼研發長鄭添祿與台灣大學醫學院臨床醫學研究所講座教授兼任台大醫院副院長高嘉宏共同獲獎。「電機／資訊／通訊」領域交通大學終身講座教授兼副校長張翼與台灣大學電機系特聘教授兼電資學院副院長吳宗霖連袂摘下；台灣大學機械系終身特聘教授陳炳煇與工業技術研究院機械與機電系統研究所所長胡竹生則在「機械／能源／環境」領域同登榮耀。值得一提的是，科技類獎七位得主有四位是「國產學者」，在國內從小學攻讀到博士，卻在各自的領域引領全球研究風潮，像是葉均蔚發明「高熵合金」，打破千古煉金鐵律，開啟材料科學研究新頁；吳宗霖研製出世界最迷你且可抑制高頻無線傳輸雜訊干擾的電路元件；鄭添祿獨步全球開發出研發抗癌新藥的抗體鎖；高嘉宏是B型與C 型肝炎病毒研究國際權威。此外，三位海歸派學者則審時度局掌握國際科研脈動，為台灣創新產業開創新局；張翼不但是臺灣砷化鎵產業「開山鼻祖」，更是三五族複合物半導體產業的「動力火車」；陳炳煇透過研究成果技轉，為台灣打造兩家躋身全世界前五大的散熱模組廠商；胡竹生在新冠肺炎（COVID-19）突襲全球的危急時刻，在40天內協助政府迅速建置口罩國家隊，使我國成為國際防疫典範。人文類獎今年以「物種保育」為遴選領域，李家維在台泥集團鼎力支持，2007年在屏東縣高樹鄉建置「辜嚴倬雲植物保種中心」，宛若台灣版的諾亞方舟，14年蒐藏接近3.4萬種熱帶和亞熱帶植物，成為全球物種最豐富的保種中心，為許多瀕臨絕種、甚至已找不到活體的植物，留下一線生機。東元科技文教基金會董事長郭瑞嵩表示，「創造力」是東元基金會的的核心價值，無論是創設「東元獎」，舉辦「Green Tech」國際競賽、或「驚嘆號」台灣原住民族群永續教育，都是以激發「創造力」為主體，這屆八位得獎者透過科研創新，不畏艱難為台灣永續發展創造新局，就是「創造力」生生不息的動能。人文類獎得主李家維以「瀕危的生命界─全球拯救行動」為題發表演講，跟所有得獎人與應邀觀禮貴賓分享各國如何透過跨國合作，遏阻並搶救因人類活動而瀕臨觸發邊緣的第六次物種大滅絕，更從「辜嚴倬雲熱帶植物保種中心」帶來40株台灣捲瓣蘭特有種與40株國家瀕危(NEN)級九九峰秋海棠，呼籲大家共同照顧愛護瀕危植物，讓保種活動開枝散葉。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201121/1859818.htm\n",
      "\n",
      "                                    2020-11-21 16:19                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 台泥雙喜臨門！國際品牌與TCSA　台泥榮獲八項大獎蟬聯傳產冠軍\n",
      "\n",
      "\n",
      "  陳心怡／台北報導台灣水泥公司雙喜臨門，甫獲得經濟部2020前25大台灣國際品牌榮譽，今（18）日更榮獲TCSA台灣企業永續獎傳統製造業及能源產業組第一名等八項大獎，再度蟬聯傳統產業冠軍。台泥表示，今年初啟動的台泥DAKA開放生態循環工廠，開啟與社會溝通的新模式，獲得社會共融與循環經濟領袖兩個獎項之雙肯定，另外，台泥推動之水泥手作工作坊，結合文創團體，將水泥材質融合工藝創作，傳遞水泥業獨有的溫度，在競爭激烈的創意溝通獎中脫穎而出。台泥董事長張安平強調：「永續的地球，人文為優先，人類的幸福是一切價值的最高標準，這些是台泥的精神。在主動尋求環保解決方案，台泥是堅定的先行者，Doing well by doing good，我們有企業的靈魂，所以我們會用力的參與二氧化碳的減排。」今天的頒獎典禮，由台泥總經理李鐘培與同仁一起出席受獎，八項大獎包括永續企業獎─傳統製造業及能源產業組第一名、中文報告書白金獎、企業卓越案例獎則在氣候領袖、循環經濟領袖、人才發展、創意溝通、社會共融以及創新成長等六項獲肯定，台泥在減碳、人才培育、社會參與及科技發展上，皆展現成果。這次獲得的獎項中，「氣候領袖獎」已連續五年獲此殊榮。台泥關注氣候變遷，積極致力產業減碳，2020年6月是東亞、大中華區第一家承諾並提前通過科學減碳目標 SBTi 審核的水泥企業，2020年9月張安平董事長與全球水泥及混凝土協會 GCCA共同發起「2050 氣候願景」，宣示2050年前達到混凝土碳中和之最積極目標。\n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201118/1857058.htm\n",
      "\n",
      "                                    2020-11-18 12:07                                \n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 謝金河／看到這個數字你會知道台灣有多棒！\n",
      "\n",
      "\n",
      "我們想讓你知道…今年第三季的淨利達到空前，這當中有幾個關鍵，一是半導體產業業績大好，單是台積電幾乎占整體獲利的兩成。二是原來虧損累累的面板及太陽能產業都翻轉賺錢。三是傳統產業龍頭都賺大錢。●謝金河／《財訊》社長兼發行人、財信傳媒董事長前幾天預告台灣上市櫃公司第三季淨利可能會出乎預料的好，我心中初估約6500億元上下，也就是比過去歷史新高，多出一點。沒想到這個數字比我心中估算的數字高出一千多億，這是難以想像的好成績。今天經濟日報公布上市櫃公司第三季淨利7694億元，季增37.1%，年增23.8%，前三季稅後淨利1.69兆元，年成長率9.2%。工商時報公布的數據是7844.28億元，季增39.78%，年增26.28%，前三季達1.7149兆元，年增10.8%，工商時報的數字比經濟日報高一些，但不管用哪個數字，這都是史上最好的獲利紀錄。從我統計的列表來看，2017及2018年，企業獲利都創下最好的2.19兆元，其實2017年台灣企業的獲利已經顯著好轉，但多數人仍看衰台灣，2017年第三季全體上市櫃公司獲利6456億元，2018年第三季淨利6523億元，每一年第三季都是年度獲利最高峰，2019年貿易戰稍影響獲利表現，全年純利降至1.98兆元，這次來到1.7兆元左右，全年可望達到2.4兆，將再創歷史新高紀錄。今年第三季的淨利達到空前，這當中有幾個關鍵，一是半導體產業業績大好，單是台積電就貢獻1373.1億元，幾乎占整體獲利的兩成，而聯發科，聯電也都創下新高紀錄。二是原來虧損累累的面板及太陽能產業都翻轉賺錢。三是傳統產業龍頭都賺大錢。台塑四寶上半年都虧損，第三季四寶加起來大賺498億元，貨櫃航運的長榮，陽明，萬海都大賺，台泥，亞泥也可圈可點，永豐餘更見爆炸式成長。再來是金控的國泰及富邦單季淨利都超過300億，把這些數字加起來，大家就知道今年第一季企業獲利撑桿跳來自何處？這些年唱衰台灣的不少，但企業努力用數字告訴大家台灣的好！熱門點閱》►鍾文榮／購書折扣：讀者的隱性資本與顯性資本之爭►丁怡銘失言》蔡詩萍／蘇貞昌院長「傲慢」之所在►RCEP衝擊》單驥／川普影響力仍在　美國將只談沒有中國的TPP？►隨時加入觀點與討論，給雲論粉絲團按個讚！●本文獲作者授權，轉載自謝金河臉書。以上言論不代表本網立場，歡迎投書《雲論》讓優質好文被更多人看見，請寄editor88@ettoday.net或點此投稿，本網保有文字刪修權。 ►防疫新生活！國內旅遊票券特價開賣！ \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201118/1856875.htm\n",
      "2020年11月18日 10:12\n",
      "=============\n",
      "\n",
      "\n",
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 台泥獲利不畏疫情逆勢成長！看好明年需求穩健\n",
      "\n",
      "\n",
      "記者陳心怡／台北報導台泥（1101）今日舉行法說會，今年營運雖受疫情影響，但台泥營收卻逆勢成長，今年前3季稅後淨利新台幣184億元，年增3.9%，毛利率33%，每股盈餘3.15元。台泥總經理李鐘培表示，台灣水泥市場2020年前三季需求年成長6-7%，主要原因為前瞻計畫之基建需求成長，以及台商回台建廠，明年看起來是相當穩定。中國市場部分，李鐘培提到，除了第一季受到疫情影響，開工日期延後了兩次，造成營運下滑，不過第2、3季水泥銷量迅速回升，且優於去年。李鐘培指出，中國大陸需求持續看好，截至2020年第三季，固定資產投資年成長0.8%、房地產開發投資年成長5.6%，以及房地產施工面積年成長3.1%。中國大陸市場供給面將持續透過錯峰生產、以及嚴禁新產能，延續供給側改革。至於台泥海外水泥市場獲利部分，李鐘培指出，土耳其上半年水泥需求量年成長 7%、第三季更優，葡萄牙前三季也成長 12%，在新冠肺炎疫情下衝擊反而成長。展望後市，台泥表示將持續專注於三個核心事業，包括水泥及新種建材、廢棄物處理以及能源。台泥董事長張安平表示，為了因應環境變化，現在擴產不單單只追求規模，而是要符合環保、綠能要求，台泥也會持續投入研發及資本支出，強化低碳水泥生產技術。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201117/1856566.htm\n",
      "\n",
      "                                    2020-11-17 19:42                                \n",
      "=============\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "產業類別: 水泥工業\n",
      "\n",
      "股票編號: 1101\n",
      "標題: 台泥張安平︰新冠病毒全世界繳了白卷　21世紀可能決定人類是否被滅絕\n",
      "\n",
      "\n",
      "記者陳心怡／台北報導台泥（1101）今（17）日召開法說會，董事長張安平致詞時表示，2020年庚子年是蝗害、天災、水災、疫情衝擊的一年，COVID-19（新冠肺炎）疫情是老天給我們的一張考卷，到目前為止大家回頭來看，還沒有解決，這個問題還沒有解決，「大家似乎繳了白卷」。張安平說，2020年也是人心覺醒的一年，突如其來，令我們不知所措的新冠病毒，一夕之間凍結了熟悉的生活節奏。疫情帶來的改變，讓大家理解到原來全球彼此依賴的程度，國際間人與人的關係竟然是如此的緊密，人和大自然是如此唇齒相依。張安平指出，今年除了疫情外，藍色地球也改變了，北半球、南半球都發生了想像不到的森林大火，沒有經歷過的水災，旱災，蝗害。張安平反思，大自然改變了嗎？氣候改變了嗎？以往的科學以及經濟發展的成功造成了問題嗎？我們鼓勵發展，鼓勵科技進步而忽略了人的生活嗎？也忽略了因為發展所帶來的社會責任嗎？他認為，每一種發展進步都有帶來連鎖的反應，歷史不會一條直線的發展下去，人類發展也是一樣，必須要經常的反省，調整，修正。張安平提到，12,000年前的農業革命，200年前的工業革命，人類在歷史中不停的改變生態，也滅絕了很多生物。但是21世紀可能會決定人類本身是不是被滅絕的生物之一。張安平說，過去200年增加太多的二氧化碳造成了地球的溫室效應，改變氣候，也改變了世界的運行 。21世紀的發展欠未來一個責任，當我們退場以後，地球的生態，社會的生存以及價值觀能夠永續長存嗎?張安平並指出，「水泥是取自於大地，用之於人類文明」的事業，但是他的原罪是較高二氧化碳的排放，強調在主動尋求環保解決方案，台泥是堅定的先行者，會用力地參與二氧化碳的減排。 \n",
      "\n",
      " 網址: https://www.ettoday.net/news/20201117/1856558.htm\n",
      "\n",
      "                                    2020-11-17 18:28                                \n",
      "=============\n",
      "\n",
      "\n",
      "sleep time: 6 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-28532b61776a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m                     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sleep time: %s sec\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m                     \u001b[0mj\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;31m#                     print(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import time as t\n",
    "import random\n",
    "import lxml\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import time as t\n",
    "import random\n",
    "import lxml\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "userAgent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0'\n",
    "headers = {\n",
    "    'User-Agent':userAgent\n",
    "}\n",
    "frame = ['標題','時間','網址','內容','產業類別','股票代號','股票名稱' ]\n",
    "id = []\n",
    "df = pd.DataFrame(columns = frame )\n",
    "\n",
    "j = 1\n",
    "\n",
    "#以下為關鍵字\n",
    "d = {}\n",
    "with open(\"comp2.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        (key, val) = line.split()\n",
    "        a = val \n",
    "        d[str(val)] = a\n",
    "values = list(d.values())\n",
    "\n",
    "# print(values)\n",
    "\n",
    "\n",
    "for c in values:#以下為關鍵字\n",
    "#     print(c)\n",
    "    search = c\n",
    "    \n",
    "    Url_Input = 'https://www.ettoday.net/news_search/doSearch.php?search_term_string='+search\n",
    "#     print(Url_Input)\n",
    "    url = Url_Input\n",
    "    #以下為股票編號\n",
    "    l = {}\n",
    "    with open(\"comp2.txt\", 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split()\n",
    "            l[int(key)] = a\n",
    "            keys = list(l.keys())\n",
    "        # print(keys)\n",
    "\n",
    "    for k in keys:\n",
    "#         print(k)\n",
    "        \n",
    "        #以下為產業類別\n",
    "        C = {}\n",
    "        with open(\"compCat.txt\", 'r', encoding=\"utf8\") as Cat:\n",
    "            for kat in Cat:\n",
    "#             print(kat)\n",
    "    \n",
    "\n",
    "\n",
    "                for i in range(0, 10):\n",
    "                    res = rq.get(url, headers=headers)\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    temp = []#設定一個字典\n",
    "                    p=0\n",
    "                    newUrl = soup.select(\"div.menu_page a\")[-2][\"href\"]\n",
    "\n",
    "                    titles = soup.select('div.box_2')\n",
    "                #     titleUrl =\n",
    "                    for i in range(7, 37, 3): #這裡開始照著網址的順序抓\n",
    "                        titleUrl = soup.select('a')[i]['href']\n",
    "                        temp.append(titleUrl)#每次會把新的網址丟到字典裡\n",
    "                    for titleTag in titles:#這裡開始抓標題\n",
    "                        title = titleTag.select_one('a')\n",
    "                    #開始抓內文\n",
    "                        res = rq.get(temp[p], headers=headers)\n",
    "                        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                        time = soup.findAll(\"time\", {\"class\":\"date\"})\n",
    "                        time = time[0].text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print('產業類別:', kat)#產業類別\n",
    "                        print('股票編號:', k)#股票編號\n",
    "                        print(\"標題:\", title.text)\n",
    "                        print('\\n')\n",
    "\n",
    "                #         print(content)\n",
    "\n",
    "\n",
    "                        for i in soup.findAll(\"div\", {\"class\": \"story\"}):            \n",
    "                            i = i.text\n",
    "                            try:\n",
    "                                a = soup.findAll(\"div\", {\"class\": \"ad_readmore\"})\n",
    "                                a = a[0].text\n",
    "                            except IndexError:\n",
    "                                pass\n",
    "\n",
    "                            try:\n",
    "                                b = soup.select(\"strong\")#圖片下的註解 #findAll不知道為啥不能用\n",
    "                                b = b[0].text\n",
    "                            except IndexError:\n",
    "                                pass\n",
    "                            result = (i.replace(str(a), ''))#去除廣告字串\n",
    "                #             print(result.replace('\\n',''))#把換行用掉\n",
    "                            result2 = result.replace('\\n','')\n",
    "                            content = result2.replace(str(b), '')\n",
    "                            print(content)#內文\n",
    "                            #以下為時間\n",
    "#                             df.loc[J] = [time, kat, k, values, title.text, temp[p], content]\n",
    "#                             df.to_csv('TeamAone.csv', index = False, encoding = 'utf_8_sig')\n",
    "#                             J +=1\n",
    "\n",
    "                #             print(a)\n",
    "                        \n",
    "\n",
    "                            \n",
    "                        df.loc[j] = [title.text, time, temp[p], content, kat, k, values]\n",
    "                        print('\\n', '網址:', temp[p])#印出網址字典的內容\n",
    "                        p+=1#下次會印出下一筆\n",
    "                        \n",
    "                        print(time)\n",
    "                        print('=============')\n",
    "                        print('\\n')\n",
    "\n",
    "#                         df.loc[J] = [time, kat, k, values, title.text, temp[p], content]\n",
    "#                         df.to_csv('TeamAone2.csv', index = False, encoding = 'utf_8_sig')# !!list if index out of range\n",
    "#                         J +=1\n",
    "\n",
    "                #         print(titleUrl)\n",
    "\n",
    "                            \n",
    "                    url = newUrl\n",
    "                #     print(newUrl)\n",
    "                    sleep_time = random.randint(3,10)\n",
    "                    sl = sleep_time\n",
    "                    print(\"sleep time: %s sec\"%(sleep_time))\n",
    "                    t.sleep(sl)\n",
    "                    j +=1\n",
    "#                     print(df)\n",
    "                    \n",
    "#                     df.loc[j] = [title.text, time, temp[p], content, kat, k, values]\n",
    "                    \n",
    "                    df.to_csv('TeamAone233.csv', index = 0, encoding = 'utf_8_sig')\n",
    "#                     df.loc[J] = [title, time, temp[p], content, kat, k, values]\n",
    "#                     df.to_csv('TeamAone.csv', index = 0, encoding = 'utf_8_sig')\n",
    "#                     J +=1\n",
    "\n",
    "\n",
    "\n",
    "userAgent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0'\n",
    "headers = {\n",
    "    'User-Agent':userAgent\n",
    "}\n",
    "frame = ['標題','時間','網址','內容','產業類別','股票代號','股票名稱' ]\n",
    "id = []\n",
    "df = pd.DataFrame(columns = frame )\n",
    "\n",
    "j = 1\n",
    "\n",
    "#以下為關鍵字\n",
    "d = {}\n",
    "with open(\"comp2.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        (key, val) = line.split()\n",
    "        a = val \n",
    "        d[str(val)] = a\n",
    "values = list(d.values())\n",
    "\n",
    "# print(values)\n",
    "\n",
    "\n",
    "for c in values:#以下為關鍵字\n",
    "#     print(c)\n",
    "    search = c\n",
    "    \n",
    "    Url_Input = 'https://www.ettoday.net/news_search/doSearch.php?search_term_string='+search\n",
    "#     print(Url_Input)\n",
    "    url = Url_Input\n",
    "    #以下為股票編號\n",
    "    l = {}\n",
    "    with open(\"comp2.txt\", 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split()\n",
    "            l[int(key)] = a\n",
    "            keys = list(l.keys())\n",
    "        # print(keys)\n",
    "\n",
    "    for k in keys:\n",
    "#         print(k)\n",
    "        \n",
    "        #以下為產業類別\n",
    "        C = {}\n",
    "        with open(\"compCat.txt\", 'r', encoding=\"utf8\") as Cat:\n",
    "            for kat in Cat:\n",
    "#             print(kat)\n",
    "    \n",
    "\n",
    "\n",
    "                for i in range(0, 10):\n",
    "                    res = rq.get(url, headers=headers)\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    temp = []#設定一個字典\n",
    "                    p=0\n",
    "                    newUrl = soup.select(\"div.menu_page a\")[-2][\"href\"]\n",
    "\n",
    "                    titles = soup.select('div.box_2')\n",
    "                #     titleUrl =\n",
    "                    for i in range(7, 37, 3): #這裡開始照著網址的順序抓\n",
    "                        titleUrl = soup.select('a')[i]['href']\n",
    "                        temp.append(titleUrl)#每次會把新的網址丟到字典裡\n",
    "                    for titleTag in titles:#這裡開始抓標題\n",
    "                        title = titleTag.select_one('a')\n",
    "                    #開始抓內文\n",
    "                        res = rq.get(temp[p], headers=headers)\n",
    "                        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                        time = soup.findAll(\"time\", {\"class\":\"date\"})\n",
    "                        time = time[0].text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print('產業類別:', kat)#產業類別\n",
    "                        print('股票編號:', k)#股票編號\n",
    "                        print(\"標題:\", title.text)\n",
    "                        print('\\n')\n",
    "\n",
    "                #         print(content)\n",
    "\n",
    "\n",
    "                        for i in soup.findAll(\"div\", {\"class\": \"story\"}):            \n",
    "                            i = i.text\n",
    "                            try:\n",
    "                                a = soup.findAll(\"div\", {\"class\": \"ad_readmore\"})\n",
    "                                a = a[0].text\n",
    "                            except IndexError:\n",
    "                                pass\n",
    "\n",
    "                            try:\n",
    "                                b = soup.select(\"strong\")#圖片下的註解 #findAll不知道為啥不能用\n",
    "                                b = b[0].text\n",
    "                            except IndexError:\n",
    "                                pass\n",
    "                            result = (i.replace(str(a), ''))#去除廣告字串\n",
    "                #             print(result.replace('\\n',''))#把換行用掉\n",
    "                            result2 = result.replace('\\n','')\n",
    "                            content = result2.replace(str(b), '')\n",
    "                            print(content)#內文\n",
    "                            #以下為時間\n",
    "#                             df.loc[J] = [time, kat, k, values, title.text, temp[p], content]\n",
    "#                             df.to_csv('TeamAone.csv', index = False, encoding = 'utf_8_sig')\n",
    "#                             J +=1\n",
    "\n",
    "                #             print(a)\n",
    "                        \n",
    "\n",
    "                            \n",
    "                        df.loc[j] = [title.text, time, temp[p], content, kat, k, values]\n",
    "                        print('\\n', '網址:', temp[p])#印出網址字典的內容\n",
    "                        p+=1#下次會印出下一筆\n",
    "                        \n",
    "                        print(time)\n",
    "                        print('=============')\n",
    "                        print('\\n')\n",
    "\n",
    "#                         df.loc[J] = [time, kat, k, values, title.text, temp[p], content]\n",
    "#                         df.to_csv('TeamAone2.csv', index = False, encoding = 'utf_8_sig')# !!list if index out of range\n",
    "#                         J +=1\n",
    "\n",
    "                #         print(titleUrl)\n",
    "\n",
    "                            \n",
    "                    url = newUrl\n",
    "                #     print(newUrl)\n",
    "                    sleep_time = random.randint(3,10)\n",
    "                    sl = sleep_time\n",
    "                    print(\"sleep time: %s sec\"%(sleep_time))\n",
    "                    t.sleep(sl)\n",
    "                    j +=1\n",
    "#                     print(df)\n",
    "                    \n",
    "#                     df.loc[j] = [title.text, time, temp[p], content, kat, k, values]\n",
    "                    \n",
    "                    df.to_csv('TeamAone233.csv', index = 0, encoding = 'utf_8_sig')\n",
    "#                     df.loc[J] = [title, time, temp[p], content, kat, k, values]\n",
    "#                     df.to_csv('TeamAone.csv', index = 0, encoding = 'utf_8_sig')\n",
    "#                     J +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
